#!/usr/bin/env python3
"""
Create Research Visualizations
==============================

Creates comprehensive visualizations from research data including
an infographic-style summary of key findings.
"""

import os
import sys
import json
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
from matplotlib.gridspec import GridSpec
import seaborn as sns
from datetime import datetime

# Add parent directory to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

def create_comprehensive_infographic(data_path: str, output_dir: str):
    """Create a comprehensive infographic of research findings"""
    
    # Load data
    with open(data_path, 'r') as f:
        data = json.load(f)
    
    # Set up the figure with a grid layout
    fig = plt.figure(figsize=(20, 24))
    gs = GridSpec(6, 3, figure=fig, hspace=0.3, wspace=0.3)
    
    # Main title
    fig.suptitle('Mental Health LLM Evaluation: Research Insights', 
                 fontsize=28, fontweight='bold', y=0.98)
    
    # Subtitle with date and dataset info
    subtitle = f"Dataset: 27 Mental Health Scenarios | 4 AI Models | {datetime.now().strftime('%B %Y')}"
    fig.text(0.5, 0.96, subtitle, ha='center', fontsize=16, style='italic')
    
    # 1. Model Selection Overview (Top Left)
    ax1 = fig.add_subplot(gs[0, 0])
    ax1.text(0.5, 0.8, '100%', ha='center', va='center', fontsize=72, 
             fontweight='bold', color='#2E86AB')
    ax1.text(0.5, 0.3, 'Claude Selected', ha='center', va='center', 
             fontsize=20, fontweight='bold')
    ax1.text(0.5, 0.1, 'Across all scenarios', ha='center', va='center', 
             fontsize=14, alpha=0.7)
    ax1.set_xlim(0, 1)
    ax1.set_ylim(0, 1)
    ax1.axis('off')
    
    # 2. Average Confidence (Top Middle)
    ax2 = fig.add_subplot(gs[0, 1])
    confidence = 0.609
    # Create a circular progress bar effect
    theta = np.linspace(0, 2 * np.pi * confidence, 100)
    r = 0.8
    x = r * np.cos(theta)
    y = r * np.sin(theta)
    ax2.plot(x, y, linewidth=20, color='#A23B72', solid_capstyle='round')
    ax2.text(0, 0, f'{confidence:.0%}', ha='center', va='center', 
             fontsize=48, fontweight='bold')
    ax2.text(0, -1.3, 'Average Confidence', ha='center', va='center', 
             fontsize=16, fontweight='bold')
    ax2.set_xlim(-1.5, 1.5)
    ax2.set_ylim(-1.5, 1.5)
    ax2.axis('off')
    ax2.set_aspect('equal')
    
    # 3. Response Time (Top Right)
    ax3 = fig.add_subplot(gs[0, 2])
    ax3.text(0.5, 0.8, '0.50s', ha='center', va='center', fontsize=48, 
             fontweight='bold', color='#F18F01')
    ax3.text(0.5, 0.3, 'Avg Response Time', ha='center', va='center', 
             fontsize=18, fontweight='bold')
    ax3.text(0.5, 0.1, 'Lightning fast!', ha='center', va='center', 
             fontsize=14, alpha=0.7, style='italic')
    ax3.set_xlim(0, 1)
    ax3.set_ylim(0, 1)
    ax3.axis('off')
    
    # 4. Model Score Comparison (Middle row, spanning 2 columns)
    ax4 = fig.add_subplot(gs[1:2, 0:2])
    models = ['Claude', 'OpenAI', 'DeepSeek', 'Gemma']
    avg_scores = [8.45, 7.79, 7.22, 7.16]
    colors = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D']
    
    bars = ax4.barh(models, avg_scores, color=colors, alpha=0.8)
    ax4.set_xlabel('Average Score (out of 10)', fontsize=14, fontweight='bold')
    ax4.set_title('Model Performance Comparison', fontsize=18, fontweight='bold', pad=20)
    ax4.set_xlim(0, 10)
    
    # Add value labels
    for i, (bar, score) in enumerate(zip(bars, avg_scores)):
        ax4.text(score + 0.1, i, f'{score:.2f}', va='center', fontsize=14, fontweight='bold')
    
    # Add grid
    ax4.grid(axis='x', alpha=0.3, linestyle='--')
    ax4.set_axisbelow(True)
    
    # 5. Prompt Type Distribution (Middle right)
    ax5 = fig.add_subplot(gs[1, 2])
    prompt_types = ['General\nSupport', 'Anxiety', 'Depression', 'Relationship']
    counts = [17, 7, 2, 1]
    colors_pie = ['#E8E8E8', '#FFE5B4', '#FFB6C1', '#98D8C8']
    
    wedges, texts, autotexts = ax5.pie(counts, labels=prompt_types, colors=colors_pie, 
                                        autopct='%1.0f%%', startangle=90,
                                        textprops={'fontsize': 12})
    ax5.set_title('Scenario Distribution', fontsize=16, fontweight='bold', pad=20)
    
    # 6. Confidence by Prompt Type (Lower left)
    ax6 = fig.add_subplot(gs[2, :])
    prompt_conf = {
        'Anxiety': 0.610,
        'Depression': 0.671,
        'General Support': 0.599,
        'Relationship': 0.658
    }
    
    x_pos = np.arange(len(prompt_conf))
    values = list(prompt_conf.values())
    labels = list(prompt_conf.keys())
    colors_conf = ['#FFE5B4', '#FFB6C1', '#E8E8E8', '#98D8C8']
    
    bars = ax6.bar(x_pos, values, color=colors_conf, alpha=0.8, edgecolor='black', linewidth=2)
    ax6.set_ylabel('Confidence Score', fontsize=14, fontweight='bold')
    ax6.set_title('Model Selection Confidence by Scenario Type', fontsize=18, fontweight='bold', pad=20)
    ax6.set_xticks(x_pos)
    ax6.set_xticklabels(labels, fontsize=12)
    ax6.set_ylim(0, 1)
    
    # Add value labels
    for bar, val in zip(bars, values):
        height = bar.get_height()
        ax6.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                f'{val:.1%}', ha='center', va='bottom', fontsize=12, fontweight='bold')
    
    # Add confidence threshold line
    ax6.axhline(y=0.65, color='red', linestyle='--', alpha=0.5, label='High Confidence Threshold')
    ax6.legend()
    ax6.grid(axis='y', alpha=0.3, linestyle='--')
    
    # 7. Cost Analysis (Lower middle row)
    ax7 = fig.add_subplot(gs[3, :2])
    cost_models = ['Claude\n(Selected)', 'OpenAI', 'DeepSeek', 'Gemma\n(Local)']
    costs = [15, 15, 2, 0]
    colors_cost = ['#2E86AB', '#A23B72', '#F18F01', '#C73E1D']
    
    bars = ax7.bar(cost_models, costs, color=colors_cost, alpha=0.8, edgecolor='black', linewidth=2)
    ax7.set_ylabel('Cost per 1M tokens ($)', fontsize=14, fontweight='bold')
    ax7.set_title('Cost Comparison Across Models', fontsize=18, fontweight='bold', pad=20)
    
    # Add value labels
    for bar, cost in zip(bars, costs):
        height = bar.get_height()
        label = f'${cost}' if cost > 0 else 'Free*'
        ax7.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                label, ha='center', va='bottom', fontsize=14, fontweight='bold')
    
    ax7.text(0.5, -5, '*Infrastructure costs apply', transform=ax7.transData,
             ha='center', fontsize=10, style='italic', alpha=0.7)
    ax7.set_ylim(0, 18)
    ax7.grid(axis='y', alpha=0.3, linestyle='--')
    
    # 8. Key Benefits Box (Lower right)
    ax8 = fig.add_subplot(gs[3, 2])
    benefits = [
        "‚úì 100% Success Rate",
        "‚úì Sub-second responses",
        "‚úì Consistent quality",
        "‚úì Empathetic care",
        "‚úì Crisis ready"
    ]
    
    ax8.text(0.5, 0.9, 'System Benefits', ha='center', va='top', 
             fontsize=18, fontweight='bold', transform=ax8.transAxes)
    
    for i, benefit in enumerate(benefits):
        ax8.text(0.1, 0.7 - i*0.15, benefit, ha='left', va='center', 
                fontsize=14, transform=ax8.transAxes, color='darkgreen')
    
    ax8.set_xlim(0, 1)
    ax8.set_ylim(0, 1)
    ax8.axis('off')
    
    # 9. Competitive Scenarios Analysis (Bottom row)
    ax9 = fig.add_subplot(gs[4, :])
    scenario_types = ['Highly Competitive\n(<0.5 point margin)', 
                      'Normal Competition\n(0.5-1.5 margin)', 
                      'Dominant Selection\n(>1.5 margin)']
    scenario_counts = [3, 24, 0]
    colors_comp = ['#FF6B6B', '#4ECDC4', '#45B7D1']
    
    bars = ax9.bar(scenario_types, scenario_counts, color=colors_comp, 
                    alpha=0.8, edgecolor='black', linewidth=2)
    ax9.set_ylabel('Number of Scenarios', fontsize=14, fontweight='bold')
    ax9.set_title('Model Selection Competition Analysis', fontsize=18, fontweight='bold', pad=20)
    
    # Add percentage labels
    total = sum(scenario_counts)
    for bar, count in zip(bars, scenario_counts):
        height = bar.get_height()
        percentage = (count / total * 100) if total > 0 else 0
        ax9.text(bar.get_x() + bar.get_width()/2., height + 0.5,
                f'{count}\n({percentage:.0f}%)', ha='center', va='bottom', 
                fontsize=12, fontweight='bold')
    
    ax9.set_ylim(0, 30)
    ax9.grid(axis='y', alpha=0.3, linestyle='--')
    
    # 10. Research Implications (Bottom)
    ax10 = fig.add_subplot(gs[5, :])
    implications_text = """
Key Research Findings:
‚Ä¢ Claude demonstrates consistent superiority in mental health contexts with 0.66-point average advantage
‚Ä¢ High consistency in model selection suggests reliable therapeutic communication patterns
‚Ä¢ Cost implications: Dynamic selection currently matches premium model costs due to Claude dominance
‚Ä¢ Future optimization: Consider hybrid approaches for information-seeking vs. emotional support scenarios
‚Ä¢ Recommendation: Claude as primary model with fallback to DeepSeek/Gemma for cost optimization
    """
    
    ax10.text(0.05, 0.95, implications_text, ha='left', va='top', 
              fontsize=12, transform=ax10.transAxes, 
              bbox=dict(boxstyle="round,pad=0.5", facecolor="#f0f0f0", alpha=0.8))
    ax10.set_xlim(0, 1)
    ax10.set_ylim(0, 1)
    ax10.axis('off')
    
    # Save the infographic
    plt.tight_layout()
    output_path = os.path.join(output_dir, 'research_infographic.png')
    plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')
    plt.close()
    
    print(f"‚úÖ Research infographic saved to: {output_path}")
    return output_path

def create_detailed_charts(data_path: str, output_dir: str):
    """Create additional detailed charts"""
    
    # Load data
    with open(data_path, 'r') as f:
        data = json.load(f)
    
    # Extract model scores for all scenarios
    all_scores = {'openai': [], 'claude': [], 'deepseek': [], 'gemma': []}
    prompts = []
    
    for item in data:
        if 'model_scores' in item:
            prompts.append(item['prompt'][:30] + '...')
            for model, score in item['model_scores'].items():
                all_scores[model].append(score)
    
    # 1. Model Performance Heatmap
    fig, ax = plt.subplots(figsize=(12, 10))
    
    # Create score matrix
    score_matrix = []
    model_names = ['Claude', 'OpenAI', 'DeepSeek', 'Gemma']
    for model in ['claude', 'openai', 'deepseek', 'gemma']:
        score_matrix.append(all_scores[model])
    
    # Create heatmap
    im = ax.imshow(score_matrix, cmap='RdYlGn', aspect='auto', vmin=5, vmax=10)
    
    # Set ticks
    ax.set_xticks(np.arange(len(prompts)))
    ax.set_yticks(np.arange(len(model_names)))
    ax.set_xticklabels(prompts, rotation=90, ha='right')
    ax.set_yticklabels(model_names)
    
    # Add colorbar
    cbar = plt.colorbar(im, ax=ax)
    cbar.set_label('Score (out of 10)', rotation=270, labelpad=20)
    
    # Add title
    ax.set_title('Model Scores Across All Scenarios', fontsize=16, fontweight='bold', pad=20)
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'model_scores_heatmap.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    # 2. Score Distribution Violin Plot
    fig, ax = plt.subplots(figsize=(10, 8))
    
    # Prepare data for violin plot
    plot_data = []
    plot_labels = []
    for model, scores in all_scores.items():
        plot_data.extend(scores)
        plot_labels.extend([model.capitalize()] * len(scores))
    
    # Create violin plot
    import pandas as pd
    df = pd.DataFrame({'Model': plot_labels, 'Score': plot_data})
    sns.violinplot(data=df, x='Model', y='Score', palette='Set2', ax=ax)
    
    ax.set_title('Score Distribution by Model', fontsize=16, fontweight='bold')
    ax.set_ylabel('Score (out of 10)', fontsize=12)
    ax.grid(axis='y', alpha=0.3, linestyle='--')
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'score_distribution_violin.png'), dpi=300, bbox_inches='tight')
    plt.close()
    
    print("‚úÖ Additional detailed charts created")

def main():
    """Main visualization function"""
    print("üìä Creating Research Visualizations")
    print("=" * 60)
    
    # Find the latest research data
    results_dir = "results/development"
    research_dirs = [d for d in os.listdir(results_dir) if d.startswith("research_data_")]
    
    if not research_dirs:
        print("‚ùå No research data found.")
        sys.exit(1)
    
    # Use the latest dataset
    latest_dir = sorted(research_dirs)[-1]
    data_path = os.path.join(results_dir, latest_dir, "research_data.json")
    output_dir = os.path.join(results_dir, latest_dir, "visualizations")
    
    os.makedirs(output_dir, exist_ok=True)
    
    print(f"üìÇ Using dataset: {latest_dir}")
    
    # Create visualizations
    print("\nüé® Creating comprehensive infographic...")
    infographic_path = create_comprehensive_infographic(data_path, output_dir)
    
    print("\nüìà Creating detailed charts...")
    create_detailed_charts(data_path, output_dir)
    
    print("\n" + "=" * 60)
    print("‚úÖ VISUALIZATION COMPLETE")
    print("=" * 60)
    print(f"üìÅ All visualizations saved to: {output_dir}")
    print("\nGenerated files:")
    for file in os.listdir(output_dir):
        if file.endswith('.png'):
            print(f"  - {file}")

if __name__ == "__main__":
    main()