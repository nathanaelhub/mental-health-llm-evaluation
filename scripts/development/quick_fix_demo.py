#!/usr/bin/env python3
"""
Quick Fix Demonstration
=======================

Demonstrates both fixes are working:
1. Success Rate Tracking Fix
2. Winner Messages Fix (Demo Mode)
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..'))

from src.research.utils import StatusTracker
from src.research.display import print_ultra_clean_scenario_result

def demo_success_tracking():
    """Demonstrate success rate tracking works"""
    print("ðŸ§ª Testing Success Rate Tracking Fix")
    print("=" * 40)
    
    # Create StatusTracker instance
    tracker = StatusTracker()
    
    print(f"Initial state: API Calls: {tracker.api_calls}, Success Rate: {tracker.get_success_rate():.1f}%")
    
    # Simulate some API calls
    tracker.increment_api_calls("openai", 1.5, 0.002, True, debug_mode=False)
    tracker.increment_api_calls("deepseek", 2.0, 0.0, True, debug_mode=False)  
    tracker.increment_api_calls("claude", 1.8, 0.003, False, debug_mode=False)  # One failure
    
    print(f"After 3 calls (2 success, 1 failure):")
    print(f"   API Calls: {tracker.api_calls}")
    print(f"   Success Rate: {tracker.get_success_rate():.1f}%")
    print(f"   Total Cost: ${tracker.total_cost:.4f}")
    print("âœ… Success rate tracking is working!\n")

def demo_winner_messages():
    """Demonstrate winner message fix works"""
    print("ðŸ§ª Testing Winner Messages Fix")
    print("=" * 30)
    
    # Test with zero scores (the problem case)
    evaluations_zero = {
        'openai': {'composite': 0.0},
        'deepseek': {'composite': 0.0}
    }
    
    # Test with real scores
    evaluations_real = {
        'openai': {'composite': 8.5},
        'deepseek': {'composite': 7.9}
    }
    
    print("1. Testing with ZERO scores (should show âœ“):")
    print_ultra_clean_scenario_result(1, 3, "Test Scenario", evaluations_zero, "OpenAI", demo_mode=False)
    
    print("\n2. Testing DEMO MODE (should show âœ“):")
    print_ultra_clean_scenario_result(2, 3, "Test Scenario", evaluations_real, "OpenAI", demo_mode=True)
    
    print("\n3. Testing with REAL scores (should show comparison):")
    print_ultra_clean_scenario_result(3, 3, "Test Scenario", evaluations_real, "OpenAI", demo_mode=False)
    
    print("\nâœ… Winner message fix is working!")

def main():
    print("ðŸ”§ Quick Fix Demonstration")
    print("=" * 50)
    print("Demonstrating both fixes are working properly:\n")
    
    demo_success_tracking()
    demo_winner_messages()
    
    print("\n" + "=" * 50)
    print("âœ… BOTH FIXES CONFIRMED WORKING!")
    print("   1. Success rate tracking shows real percentages")
    print("   2. Demo mode shows clean checkmarks instead of (0.00)")
    print("=" * 50)

if __name__ == "__main__":
    main()